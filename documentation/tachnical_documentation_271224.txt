Overview

This project is designed to help users identify and prioritize tasks across multiple concurrent projects in a structured, data-driven way. It leverages:
	1.	A set of tasks stored in JSON files (e.g., inbox_tasks.json) or retrieved from an external service (like Todoist).
	2.	A local or GitHub-based data repository for storing feedback logs, interaction data, and other metrics.
	3.	A Flask-based server that exposes a simple web front-end for queries and suggestions.
	4.	A Large Language Model (LLM) integration (currently via Google’s Gemini model API) to generate actionable next-step suggestions.

By periodically analyzing tasks, user interactions, and temporal patterns, this system produces recommendations on which tasks are most urgent or beneficial to focus on.

System Architecture

At a high level, the ProjectM system is composed of the following major modules and files:
	1.	projectM.py:
	•	Main Python application that orchestrates data flow, scheduling, and user requests.
	•	Contains the core classes (e.g., TaskAnalysisService, GitHubActivityMonitor, UserInteractionTracker, FeedbackCollector, FeedbackRepository, LLMService, etc.).
	•	Defines the Flask server routes to handle user queries at /api/query.
	2.	Shell scripts (various .sh files):
	•	start_server.sh: Activates a conda environment and starts the Python application (projectM.py) on port 5001.
	•	sync_inbox.sh & sync_all.sh: Scripts to sync local JSON tasks with a GitHub repository (via sync_local_to_github in projectM.py).
	3.	createTasks.py:
	•	A small Python script that connects to the Todoist API (or another service) to fetch tasks and save them locally (inbox_tasks.json).
	•	Useful for exporting tasks from an external source into this system’s structure.
	4.	templates/index.html:
	•	Minimal front-end interface. This web page includes a text box for queries and a display area for LLM-generated suggestions or errors.
	5.	Various data and feedback files:
	•	tasks/: Contains text files describing or detailing each project. For example:
	•	project_CAUSALFound.txt, project_timeAwareFoundationModel.txt, etc.
	•	Each file contains an overview, current status, and context references.
	•	inbox_tasks.json holds the list of tasks retrieved from external sources.
	•	feedback/: Where real-time feedback data is stored:
	•	action_outcomes.jsonl: Stores user interactions or outcomes in JSONL form.
	•	success_patterns.json: Summaries of success or performance metrics.
	•	temporal_analysis.json: Contains stats on completions by hour/day, average completion times, etc.
	•	previous_tasks.json: Holds a snapshot of tasks from the previous sync to detect changes.
	6.	data/:
	•	Mirrors files from feedback/ but is used by the application as a local data store. E.g., temporal_analysis.json, action_outcomes.jsonl, and success_patterns.json.
	7.	development_folder/:
	•	Contains additional dev artifacts or prompts, e.g. pseudocode.txt, o1pro_prompt.txt, etc.
	•	Not essential to production usage, but documents the iterative development or prompting approach.

Primary Functional Components

1. Task Analysis and Management

Key Classes:
	•	TaskAnalysisService
	•	monitor_task_changes(self, previous_tasks, current_tasks)
	•	Compares a previous tasks snapshot with the current tasks list.
	•	Identifies completed tasks (those no longer present), modifications (changed details like priority or description), and possible downstream tasks (i.e., tasks that can now proceed if dependencies were completed).
	•	analyze_completion_patterns(self, task_history)
	•	Computes overall metrics about task completion: average completion time, success rate, or frequency of tasks completed by priority.

2. GitHub Repository Integration

Key Classes:
	•	GitHubResourceManager and GitHubActivityMonitor
	•	GitHubResourceManager handles authentication and resource retrieval from the GitHub API.
	•	GitHubActivityMonitor.track_related_activity(self, task_id, timeframe) can look for commits, PRs, or issues referencing a given task ID within a certain timeframe.
	•	These classes also manage rate-limiting and caching for efficiency.

3. User Interaction Tracking

Key Class:
	•	UserInteractionTracker
	•	track_interactions(self, suggestion_id): Logs events (like user acceptance, rejection, or modifications) about the LLM’s suggestions.
	•	Adds data to action_outcomes.jsonl (via the FeedbackRepository).

4. Temporal Analysis

Key Class:
	•	TemporalAnalysis
	•	analyze_patterns(self, historical_data): Aggregates data by hour of day or day of week.
	•	Identifies when tasks are most likely to be completed, which time windows yield the highest success rate, etc.

5. Feedback Collection and Storage

Key Classes:
	•	FeedbackCollector
	•	collect_feedback(self, suggestion_id): Collates data from TaskAnalysisService, GitHubActivityMonitor, UserInteractionTracker, and TemporalAnalysis.
	•	aggregate_feedback(…) merges multiple sources into a single structure.
	•	FeedbackRepository
	•	update_outcomes(self, feedback_data): Appends new feedback data to action_outcomes.jsonl.
	•	update_patterns(self, new_patterns): Merges success_patterns.json with newly discovered patterns.
	•	update_temporal(self, temporal_data): Updates temporal_analysis.json with time-based analytics.

6. Context Aggregation and LLM Interaction

Key Classes:
	•	ContextAggregator
	•	aggregate_context(self, query, repo_contents): Gathers user query + repository tasks + feedback metrics for an LLM prompt.
	•	get_feedback_context(self): Loads feedback data from the local JSON/JSONL files, returning outcomes, success patterns, and temporal data.
	•	LLMService
	•	generate_suggestion(self, context):
	1.	Constructs a prompt from the user query and context data.
	2.	Issues a POST request to the Gemini model endpoint.
	3.	Parses and returns the generated text suggestion.

7. Core Application Flow

Key Class:
	•	ActionSuggestionSystem
	•	process_query(self, user_query):
	1.	Reads data from the GitHub repo (e.g., tasks, feedback logs).
	2.	Aggregates context via ContextAggregator.
	3.	Calls the LLM (LLMService) to generate a suggestion.
	4.	Logs the suggestion in the user interaction tracker.
	5.	Returns the suggestion.
	•	update_feedback(self):
	•	Periodically (via cron or scheduling) collects feedback from multiple modules.
	•	Stores them in feedback/ JSON/JSONL files, optionally commits them to GitHub.

Deployment and Runtime Instructions
	1.	Environment Setup:
	•	Requires Python 3.8+ (ideal: use Conda or venv).
	•	Install dependencies such as requests, flask, PyGithub, python-dotenv, etc.
	2.	Configuration:
	•	.env file with environment variables:
	•	GITHUB_TOKEN: For accessing/updating the GitHub repository.
	•	GOOGLE_API_KEY: For making requests to Google’s Gemini endpoint.
	•	TODOIST_API_KEY: (optional) If using the createTasks script to fetch tasks from Todoist.
	•	Within projectM.py, you can modify or confirm:
	•	GITHUB_REPO to point to the correct <username>/<repo-name>.
	3.	Starting the Server:
	•	Run ./start_server.sh. This does:
	1.	Activates the projectM conda environment.
	2.	Sets PYTHONPATH to ensure modules can be imported.
	3.	Executes projectM.py (Flask server on port 5001 by default).
	•	Once running, open a browser to http://localhost:5001.
	4.	Syncing Tasks:
	•	sync_inbox.sh: Pulls only inbox_tasks.json changes from local to GitHub (via Python function sync_local_to_github('inbox')).
	•	sync_all.sh: Syncs all .json and .txt files under tasks/.
	5.	Cron-like Scheduling:
	•	The application provides convenience functions for scheduling:
	•	hourly_task_sync(): Called once an hour to read new tasks, compare with old tasks, then store changes.
	•	daily_pattern_analysis(): Called once a day to analyze patterns and store them in success or temporal logs.
	•	You can call these in a real cron job or with external scheduling tools.

Usage Example
	1.	Add or Import Tasks:
	•	(Optional) Use createTasks.py to fetch tasks from Todoist. They get saved into tasks/inbox_tasks.json.
	•	Or manually place tasks in tasks/inbox_tasks.json.
	2.	Run the Server:

./start_server.sh

	•	Flask listens at port 5001.

	3.	Open the Web Interface:
	•	Visit http://localhost:5001.
	•	Enter a query, e.g.:

Which tasks should I focus on in the next 3 days?


	4.	System Workflow:
	•	ActionSuggestionSystem.process_query() triggers:
	1.	Data loading from local GitHub or memory caches.
	2.	Context aggregator merges tasks + feedback data.
	3.	LLMService sends a request to Gemini with the combined context.
	4.	Returns suggestions on the webpage.
	5.	Check and Commit:
	•	After you see suggestions or changes, you can run:

./sync_inbox.sh

to push updated tasks to GitHub or do a fuller sync with sync_all.sh.

File-by-File Explanation

projectM/
├── tasks/
│   ├── ...            # text files containing project descriptions (CAUSALFound, NWLondon, etc.)
│   ├── inbox_tasks.json
│   └── ...
├── projectM.py        # Main Python application with Flask server and class definitions.
├── start_server.sh    # Activates conda environment and starts projectM.py
├── sync_inbox.sh      # Syncs only 'inbox_tasks.json' to the GitHub repo
├── sync_all.sh        # Syncs all .json/.txt tasks in 'tasks/' to GitHub
├── feedback/
│   ├── action_outcomes.jsonl  # User interaction logs stored line by line
│   ├── success_patterns.json   # Summaries of success metrics
│   ├── temporal_analysis.json  # Time-based metrics
│   └── previous_tasks.json     # Snapshot used to detect modifications
├── README.md          # Basic readme (top-level project notes)
├── development_folder/
│   ├── pseudocode.txt # Early references for the architecture
│   └── ...
├── templates/
│   └── index.html     # The minimal front-end UI
├── createTasks.py     # Script to fetch tasks from Todoist or another service
└── data/
    ├── success_patterns.json
    ├── temporal_analysis.json
    └── action_outcomes.jsonl

Implementation Details

Flask Server and Endpoints
	•	The server is launched in projectM.py using:

app = Flask(__name__, static_folder='static')
CORS(app, resources={r"/api/*": {"origins": "*"}})

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/api/query', methods=['POST'])
def handle_query():
    data = request.json
    query = data.get('query', '')
    ...
    system = initialize_system()
    suggestion = system.process_query(query)
    return jsonify({'success': True, 'suggestion': suggestion})


	•	The front-end calls /api/query with a JSON object like:

{"query": "Which tasks should I focus on this week?"}


	•	The server returns JSON with {'success': True, 'suggestion': <response>} or an error.

LLM Integration (Gemini)
	•	The LLMService performs an HTTP POST to the Gemini model endpoint:

response = requests.post(
    self.gemini_endpoint,
    headers={"Content-Type": "application/json"},
    json=payload
)


	•	payload is structured according to Google’s generative language API:

{
  "contents": [
    {
      "parts": [
        {"text": "...Prompt text..."}
      ]
    }
  ]
}


	•	The response is parsed for candidates[0].content.

Data Persistence
	•	All user interactions (suggestion acceptance, rejections, modifications, etc.) get appended to action_outcomes.jsonl.
	•	Summaries of patterns or analysis results get saved into success_patterns.json or temporal_analysis.json.
	•	The application can optionally commit these file changes to a GitHub repository if desired.

Scheduling Jobs
	•	hourly_task_sync(task_analyzer)
	1.	Reads current tasks from inbox_tasks.json.
	2.	Loads previous tasks from previous_tasks.json.
	3.	Compares them with TaskAnalysisService.monitor_task_changes().
	4.	Logs changes to action_outcomes.jsonl.
	5.	Overwrites previous_tasks.json with the current tasks for next iteration.
	•	daily_pattern_analysis(task_analyzer, temporal_analyzer, feedback_repo)
	1.	Gathers all tasks as “task_history”.
	2.	Runs task_analyzer.analyze_completion_patterns to compute completion stats.
	3.	Runs temporal_analyzer.analyze_patterns to compile day/hour usage patterns.
	4.	Calls feedback_repo.update_patterns and feedback_repo.update_temporal with the computed data.

Recommended Customizations and Extensions
	1.	Advanced Dependencies:
	•	Link tasks by IDs so that a completed event for one task triggers new tasks to become active.
	2.	Graphical Dashboard:
	•	Visualize or chart the data from temporal_analysis.json and success_patterns.json to track progress over time.
	3.	Integration with Additional Services:
	•	Slack or email notifications for new suggestions or high-priority tasks.
	•	Additional code-literate tools like GitLab, Jira, or Trello if desired.
	4.	Authentication / Multi-User:
	•	The current approach is single-user or single context. If multiple people will share the system, then track each user’s tasks and custom suggestions separately.
	5.	Enhanced LLM Chain:
	•	Currently the system does one LLM call. Could expand to more advanced chain-of-thought or retrieval augmented generation.

Troubleshooting and Common Pitfalls
	1.	Rate Limits:
	•	Repeated calls to GitHub or Gemini might trigger rate-limiting. The code includes a StateManager to track request usage and wait if necessary.
	2.	File Writing Permissions:
	•	Ensure the system user has write permissions to local feedback/ and tasks/ directories.
	3.	Environmental Variables:
	•	Verify .env files or environment variables are properly loaded. Missing tokens result in authentication failures.
	4.	Gemini Model Availability:
	•	Ensure the relevant Google Cloud project is set up with generative language API access. Check your assigned quota and endpoints.

Conclusion

This LLM-driven project management application offers a flexible way to unify tasks, user interactions, and time-based insights, generating prioritized suggestions with minimal overhead. By maintaining a robust feedback loop and storing data in local or GitHub-hosted JSON/JSONL files, the system can adapt to multiple usage patterns, from personal to organizational scales. The modular design also allows for easy integration with other tools, additional analytics, or extended LLM prompts as your workflow evolves.