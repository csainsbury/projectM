 AI-Powered Clinical Trials: Emulating Real-World GLP-1 Efficacy in Type 2 Diabetes with Virtual Patient Populations
Mr. Calum R. MacLellan, M.Eng.1; Mr. Hristo Petkov, B.Sc.2; Dr. Conor McKeag, MBChB, M.Sc.3; Professor Feng Dong, Ph.D.2; Professor David J. Lowe, MBChB, M.D.4,5; Professor Roma Maguire, Ph.D.2; Dr. Sotiris Moschoyiannis, Ph.D.6; Professor Jo Armes, Ph.D.7; Professor Simon S. Skene, Ph.D.7; Mr. Alastair Finlinson, B.Sc.6; Dr. Christopher Sainsbury, MBChB, M.D.3
Author Affiliations: 1Department of Biomedical Engineering, University of Strathclyde, Glasgow, UK; 2Department of Computer and Information Sciences, University of Strathclyde, Glasgow, UK; 3Diabetes Centre, NHS Greater Glasgow and Clyde, Glasgow, UK; 4Institute of Health & Wellbeing, University of Glasgow, Glasgow, UK; 5Emergency Department, Queen Elizabeth University Hospital, Glasgow, UK; 6Department of Computer Science, University of Surrey, Guildford, UK; 7Surrey Clinical Trials Unit, University of Surrey, Guildford, UK.


Abbreviations: (RCT) Randomized Control Trial; (T2DM) Type 2 Diabetes Mellitus; (GLP-1) Glucagon-like Peptide-1; (SBP) Systolic Blood Pressure; (BMI) Body Mass Index; (AI) Artificial Intelligence; (DAG) Directed Acyclic Graph; (GAN) Generative Adversarial Network; (DiD) Difference-in-Differences; (RWE) Real-World Evidence.
Keywords: Generative AI, Virtual Patients, Randomized Control Trials, Virtual Clinical Trials, Clinical Trial Emulation, GLP-1 Efficacy, HbA1c, LEAD-5 emulation.
Corresponding Author: Calum R. MacLellan, University of Strathclyde, 26 Richmond Street, Glasgow, G1 1XH, UK; Email: calum.maclellan@strath.ac.uk.

Funding Source: This work was supported by the Medical Research Council (grant number MR/X005925/1).
Conflict-of-Interest Disclosure: None.
Acknowledgements: None.
Figures and Tables Count: 1 Figure, 3 Tables.















Abstract
Background: Randomized controlled trials (RCTs) remain the benchmark for assessing treatment effects but are limited to phenotypically narrow populations by design. We introduce a novel generative artificial intelligence (AI) algorithm that infers effect size through virtual clinical trials, which can emulate the RCT process and potentially extrapolate into wider populations. We validate the virtual trials by comparing the predicted impact of glucagon-like peptide-1 (GLP-1) agonists on HbA1c in type-2 diabetes (T2DM) with its true efficacy established in the LEAD-5 trial.
Methods: We designed our algorithm to learn treatment effects from real-world evidence data by a combined generative AI and causal learning approach.  Training data comprised pre- and post-treatment outcomes for 5,476 people with T2DM. We considered three treatment arms: GLP-1 (Liraglutide), basal insulin (glargine), and placebo. After training, virtual trials were conducted by sampling 232 virtual patients per arm (according to the LEAD-5 inclusion criteria) and predicting post-treatment outcomes. We used difference-in-differences (DiD) for pairwise comparisons between arms. Our goal was to emulate LEAD-5 by demonstrating a significant DiD in post-treatment HbA1c reduction for GLP-1 compared to basal insulin and placebo. 
Results: We found significant differences in HbA1c reduction for GLP-1 vs basal insulin (-1.21 mmol/mol; p<0.001) and GLP-1 vs placebo (-2.58 mmol/mol; p<0.001) in our virtual populations, consistent with LEAD-5 (Liraglutide vs glargine: -0.24%; p=0.0015, Liraglutide vs placebo: -1.09%; p<0.0001). 
Conclusions: AI-powered clinical trials can emulate RCTs in important measurements for T2DM. Our algorithm is specialty agnostic and can explore counterfactual questions, making it suitable for further study in the generalizability of RCT results in real-world populations to support clinical decision-making and policy recommendations.

Introduction 
The randomized controlled trial (RCT) is widely regarded as the gold standard for assessing the effect size of therapeutic agents on an outcome of clinical interest [1-4]. By design, they implement specific inclusion and exclusion criteria, intentionally limiting the phenotypic range of participants involved. However, the real-world patient population with Type 2 diabetes (T2DM) is phenotypically diverse and frequently presents with multiple complications and other existing co-morbidities, which are often under-represented in RCT cohorts. This discrepancy between the controlled environment of RCTs and the more diverse real-world scenarios raises questions about whether effect sizes observed in practice-defining RCTs are truly applicable to patients encountered in routine clinical practice. Moreover, RCTs are resource intensive: forming intervention groups spanning a broad range of therapies, each with diverse populations, and sufficiently sized to carry statistical significance, becomes increasingly challenging as the study scale grows. Together, both factors in RCTs for T2DM — deviating from real-world populations and scalability — limit the extent to which we can confidently make causal statements about the effect size in clinical practice.

Real-World Evidence (RWE) studies using clinical practice data present an opportunity to investigate effect size across phenotypes that extend beyond those explored within an RCT, given appropriate methodologies [5-7]. However, RWE databases are inherently observational, meaning any attempt to emulate a target trial with RWE data is still restricted to the specific eligibility criteria of the trial of interest. In other words, although we can interpret treatment effects from real-world data, we have a limited capacity to directly emulate interventions and confirm a wide range of new hypotheses that lie outside  an RCTs remit. To the best of our knowledge, the current body of research lacks the tools necessary to generalize RCT results to wider populations.

To overcome these issues, we propose to develop a predictive model that incorporates the RCT process into a virtual environment, enabling the interpretation of interventions and treatment effects from virtual populations. Two design criteria must be satisfied to achieve this. First, the model requires an understanding of the mechanisms connecting interventions made on the real-world populations to their corresponding effects. Second, the model must be able to produce ‘realistic’ virtual populations, in the sense that they sufficiently represent the variables describing the clinical data of the real-world populations. In this paper, we develop a model based on generative artificial intelligence (AI) that satisfies both requirements. More specifically, we use generative adversarial networks (GANs) [8] to construct a virtual target trial emulation model that learns to generate realistic T2DM populations for performing targeted trials. This is achieved through an optimization process that minimizes the discrepancy between two sets of distributions: one representing the RWE data, and the other describing the virtual data generated by the GAN (Fig. 1). We modify the original GAN architecture to incorporate the causal relationships amongst the data using directed acyclic graphs (DAG). This enables us to learn the causal effect of treatments from real-world observational data in T2DM populations. The resulting algorithm constitutes our trial emulation model, and we demonstrate its effectiveness to perform virtual targeted trials by emulating the findings of an established RCT in diabetes research, namely, the LEAD-5 trial [9]. 

The core of the emulation model encodes causal relations among diabetic treatments and patient clinical data into its data generating process, while controlling for known confounding variables (e.g. patients’ demographics, clinical measurements, and treatment history) by setting them to meet trial eligibility criteria. Following the RCT framework, the effect size can then be estimated by randomly allocating the virtual populations to different treatment arms and computing pair-wise differences in outcomes. We show that our AI model correctly identifies the reductive effects of liraglutide on HbA1c levels and bodyweight established in LEAD-5, compared to relevant control groups. We also examine the treatment effects in real-world populations, and find that, as expected, the conclusions of LEAD-5 are free to change as we move outside the trial criteria. Our emulation model therefore provides a promising framework to extrapolate RCT results into wider, more phenotypically diverse T2DM populations currently out-of-reach in practice, which has strong implications to support treatment decision-making at the patient-level and for broader policy recommendations.


Figure 1: Workflow of the proposed AI-powered target trial emulation model. (Top). The model learns treatment effects from a real-world observational dataset by improving its data reconstruction quality through a distance minimization between the real and synthetic (virtual) data, where synthetic samples are drawn from a generative directed acyclic graph (DAG) that jointly models the marginal distributions (GAN) and causal relationships amongst its features. (Bottom). After training, we sample virtual populations according to some known RCT inclusion criteria and use the model to simulate the effect of treatment under different interventions (i.e., emulating the real trial results). We call this process virtual trial emulation.
Methods We sought to emulate the findings of the LEAD-5 trial (Liraglutide Effect and Action in Diabetes, [9]) within our virtual trial populations. The goal in LEAD-5 was to confirm whether liraglutide, a glucagon-like peptide-1 (GLP-1) receptor agonist, caused a greater reduction in HbA1c and bodyweight compared to insulin glargine and placebo in people with T2DM. To estimate the effect of treatment within our virtual environment, the virtual populations were first generated according to the trial inclusion criteria of LEAD-5, and then randomly assigned to one of three LEAD-5 treatment arms: placebo, basal insulin (glargine), or GLP-1 (liraglutide). We used protein pump inhibitors or statins as our inactive comparators. Following LEAD-5, each arm was in combination with metformin and sulfonylurea.
Training dataset and pre-processing 
We prepared a training dataset for our AI model that reflected clear causal signals between the interventions and clinical outcomes. For training, we used the SCI Diabetes dataset hosted on the Glasgow SafeHaven platform [10], which comprises an inclusive regional cohort of individuals with diabetes containing a broad range of longitudinal demographic, phenotypic, biochemical and screening data. There are approximately 300K individuals with diabetes, where 3K individuals with MODY (Maturity-onset diabetes of the young) are recorded with certainty (genetic information) along with records of individuals with negative genetic test results. The dataset consists of an array of variables for clinical measurements, drug prescriptions, and demographics for 56,476 unique patients with T2DM. We selected a subset of these variables according to the LEAD-5 outcomes, specifically, plasma glucose (HbA1c: mmol/mol), body mass index (BMI: kg/m2), and systolic blood pressure (SBP: mmHg), in addition to other relevant features such as urine albumin-to-creatinine (UAC) ratio, estimated glomerular filtration rate (eGFR), cholesterol, and creatinine levels. Table 1 provides an overview of the clinical variables and patient characteristics relevant to LEAD-5.


To train our AI model, we prepared the dataset to represent each patient’s full treatment record as a series of pre- and post-treatment measurements collected over time. Each new treatment marks a distinct point in time, allowing us to distinguish clear responses to individual treatments and to account for all drugs administered up to that point. The result is a set of variables to represent treatment history, each encoded as a binary indicator for their presence (1) or absence (0). For the rest of the paper, we refer to the pre- and post-treatment clinical features as pre-and post-features, respectively. Given a distinct treatment and associated timestamp, pre-features were collected from 9 months prior to intervention, and post-features within a subsequent period of 12 months. If multiple measurements were collected during these periods, we used their median values. Each set of pre- and post-features was therefore presumed independent of those at previous time-steps.

AI model 
We designed our AI model to unify recent developments in machine learning-based generative modelling and causal structure learning within a single framework. Specifically, we combined the Wasserstein GAN architecture (WGAN-GP) [11] with the NOTEARS-MLP method [12]. By involving the causal dependencies between the data variables from NOTEARS-MLP within the WGAN-GP architecture, we learn how to simulate the true generative process underpinning the real-world data. This is achieved through an extensive training process that solves a distance minimisation problem between the real and generated data (Fig. 1, top). During training, the AI model learns to represent the causal structure as a directed acyclic graph (DAG), which maps out the treatment effect while adjusting for confounders (such as age and medical history) that can influence both treatment assignment and outcomes (Fig. 1, top). This understanding is crucial for virtual trial emulation: by disentangling the direct and indirect influences of these confounders, we enable accurate estimation of treatment effects across diverse populations. The resulting framework allows us to generate synthetic (virtual) patients from the causal mechanisms among treatments, patient data, and known confounders (i.e., common causes) to simulate the effect of treatment in a purely virtual manner (Fig. 1, bottom).
Virtual trial emulations 
Given the trained AI model, we performed virtual trial emulations by generating a cohort of virtual patients that satisfied the LEAD-5 inclusion criteria, outlined in Table 1. We assume independent normal distributions for the demographic variable (age) and pre-features and study the effect in the primary outcome of LEAD-5, namely, changes in starting HbA1c. We also examine the effects on bodyweight (BMI) and systolic blood pressure (SBP), which form the secondary outcomes of LEAD-5. 
To match the group sizes in LEAD-5, we randomly assigned n=232 virtual patients to one of our three intervention groups (i.e., placebo, glargine, or GLP-1). As with treatment assignment in an RCT, our sampling ensures that we eliminate any confounding and thus prevent bias in the estimation of the drug effects for enabling meaningful group comparisons (since all virtual patients have similar conditions prior to treatment). Once the pre-treatment and drug variables are assigned, the model calculates the post-treatment measurements of the virtual patients, yielding full records of the virtual patients in each group. The trial results are computed as the mean and standard deviation over 60 random seeds. We used the difference-in-differences (DiD) method [13] to quantify pairwise comparisons in outcomes between each group.
Counterfactual emulations 
We conducted a complementary study based on counterfactual emulations, which examine clinical questions about hypothetical treatment scenarios. For example: “Would this patient have developed a better outcome if they were given a different treatment?”. In other words, we compute the post-features in response to treatments different to those prescribed in practice. 
Specifically, we emulate counterfactual treatments where different drugs are applied to the same real patients from our observational dataset (SCI-Diabetes). In our experiments, we identified patients in SCI-Diabetes according to the drugs they received in practice. Then, for each real patient, the virtual trial proceeds by administering each of our three treatments and computing the pairwise DiD between each group. Importantly, recall the statistically significant differences between the SCI-Diabetes and LEAD-5 features (Table 1), which imply expected changes in effect size between the patient cohorts compared to those sampled from the LEAD-5 criteria.

ResultsVirtual trial emulations
We present our main results in Table 2, which summarises the LEAD-5 findings we aimed to emulate, together with the corresponding predictions from our AI model.
HbA1c.  LEAD-5 established that Liraglutide reduced HbA1c significantly compared with both glargine (−0.24% difference; p=0.0015) and placebo (−1.09% difference; p<0.0001). Through pairwise comparisons with DiD, we found our AI model predicted GLP-1 to produce a significant HbA1c reduction compared to both basal insulin (-1.21 mmol/mol difference; p<0.001), and placebo (-2.58 mmol/mol difference; p<0.001). Although the effect sizes are different compared to LEAD-5, the AI model identifies the correct ranking amongst the treatment arms.
Bodyweight. LEAD-5 also demonstrated that Liraglutide produced significantly greater weight loss compared with both glargine (−3.43 kg difference; p<0.0001)  and placebo (–1.39 kg difference; p = 0.0001). We performed a similar analysis using body mass index (BMI) and found that our model provides a similar conclusion: GLP-1 reduced BMI significantly compared to both basal insulin (-0.79 kg/m2 difference; p<0.001) and placebo (-0.61 kg/m2 difference; p<0.001). What was different with our virtual trials, however, was that BMI increased in all treatment arms, instead of reducing bodyweight as in LEAD-5. In our case, GLP-1 produced a significantly smaller weight gain compared with glargine and placebo. We consider possible reasons for this observation in the Discussion section.


Systolic blood pressure. LEAD-5 demonstrated a significant reduction in SBP compared with glargine (−4.5 mmHg difference, p = 0.0001), but not with placebo (p = 0.0791). Our simulations suggest GLP-1 reduces SBP significantly more than basal insulin (-2.99 mmHg difference; p<0.001) and with GLP-1 vs placebo (-2.38 mmHg difference; p<0.001). Our model’s predictions match the LEAD-5 conclusions only for the difference between GLP-1 and basal insulin, but not between GLP-1 and placebo.


Counterfactual emulations
Given that our model can carry out virtual trials that strongly adhere to LEAD-5, we are now well-positioned to use the model to examine our proposed counterfactual scenarios. Our goal here is to demonstrate whether, by stepping outside of the LEAD-5 criteria, and administering alternative treatments to a set of real patients from SCI diabetes, we arrive at different conclusions to our emulations. We present the counterfactual results in Table 3.

Overall, we find that across the real treatment groups, the effect of intervention is most obvious in HbA1c, while blood pressure and BMI remain relatively unchanged from the previous virtual trial emulations (Table 2). Two key observations arise in the HbA1c comparisons: (1) when we treat SCI-Diabetes patients belonging to the GLP-1 group with basal insulin (Table 3, GLP-1 column), we find significantly greater HbA1c reduction compared with GLP-1 (GLP-1 vs insulin: 0.64 mmol/mol difference; 95% CI: 0.34, 0.94: p<0.001); (2) compared with GLP-1, patients belonging to the real basal insulin group (Table 3, Basal insulin column) benefit more from both placebo (GLP-1 vs placebo: 0.10 mmol/mol difference; 95% CI: -0.17, 0.37) and basal insulin (GLP-1 vs insulin: 1.10 mmol/mol difference; 95% CI: 0.83, 1.36: p<0.001) in terms of lower HbA1c, though the result with placebo is not significant (p=0.472). The implications of these findings are intriguing, but hardly surprising: GLP-1 is not always the most effective treatment. For these experiments, we operate within different initial conditions to those specified by LEAD-5, particularly with HbA1c (Table 1). The benefits of GLP-1 are therefore only clear when we intervene on phenotypically narrow cohorts: when we relax these conditions as we do here, the conclusions are free to change. The result is not unique in of itself. The novelty is that it was discovered automatically by our AI model, based on the causal structure learned from RWE data.
Discussion 

Our experiments demonstrated that when patients met the LEAD-5 inclusion criteria (Table 1), the virtual trial emulations produced the same ranking between the three treatment arms in LEAD-5 [9], suggesting that GLP-1 produces more favourable patient outcomes in terms of HbA1c, BMI, and SBP reduction. However, the counterfactual experiments with real patients who did not fall into the baseline characteristics of LEAD-5 (Table 3) presented different performance rankings between the drugs. For example, amongst patients who received basal insulin in practice, the simulations revealed GLP-1 to be less effective than basal insulin for reducing HbA1c. The difference in performance ranking suggests that LEAD-5 trial outcomes cannot be simply extrapolated to cover other patient populations. Our AI model therefore has the potential to provide useful evidence for examining the generalizability of RCT results for real-world clinical practice.
Overall, our emulations closely replicated the conclusions of LEAD-5 for HbA1c and BMI. However, we observed a discrepancy in the effect of GLP-1 vs placebo on SBP: where LEAD-5 found no significant difference, our emulation suggested otherwise. In addition, The specific effect size among individual drugs was also exaggerated in most cases. We believe that the following differences between the real (LEAD-5) and virtual (AI) trial emulations were responsible for these discrepancies:  
The SCI-Diabetes data presents the key drug of interest as GLP-1, which is more general than the specific drug (i.e. Liraglutide) tested in LEAD-5. Hence the training of the emulation model, and the testing with the trial emulations, have aggregated the mean effect of several GLP-1 drugs within a single drug category. Moreover, both basal insulin and placebo are involved as drug categories in the emulations, which are not identical to the corresponding drugs involved in the original trials in LEAD-5 (i.e., insulin glargine and liraglutide placebo, respectively). 
The SCI-Diabetes dataset considered different measurement units to LEAD-5 for HbA1c and bodyweight; LEAD-5 considered HbA1c [%] and bodyweight [kg], whereas SCI-Diabetes considered HbA1c [mmol/mol] and BMI [kg/m2]. Note also that we measured changes in BMI rather than bodyweight, meaning comparisons were not completely representative.
Although the emulations have tried to re-create the LEAD-5 trial populations (Table 1), it is not possible to replicate a completely identical cohort due to different settings between the trial and the real-world clinical practice. For example, we have only used age to describe the patient demographics. 

Limitations
We acknowledge several limitations in our technological and data pre-processing methodology: 
We sampled synthetic patients from the model using a simplistic random-based approach that assumes no confounding between the pre-measurements.  A more complete and principled generation approach would be to instead learn the causal structure amongst the pre-features first, and then generate the features before producing the post-measurements. 
Our data pre-processing may have introduced errors into the training of the emulation model. For example, our pre- and post-treatment features were based on yearly median values, which may have obscured fine-grained treatment effects. Additionally, we removed all incomplete entries in the training data. This decision enabled us to preserve the causality of the real-world evidence data, but at the cost of significantly reducing the total and per-drug sample sizes. The training dataset was limited to a sample size of around 7000 once inclusion criteria were applied. Limited training data (described above) led to the drug classes of interest (i.e., placebo, basal insulin, and GLP-1) being under-represented, with only 382, 391, and 482 samples in each, respectively, compared to others (e.g., metformin with c. 1500 samples). 


Conclusions 
How RCT results for diabetes translate into real-world phenotypically diverse populations remains an open question. To make a first step in this direction, we developed a novel generative AI algorithm to perform clinical trials on T2DM patients within a virtual space. We showed that our algorithm successfully emulated the main conclusions of a real RCT in diabetes research, namely, the LEAD-5 trial [9]. We then used our algorithm to investigate counterfactual treatment scenarios that extrapolate treatment effects to populations out with LEAD-5. We discovered that the main finding of LEAD-5 did not translate into phenotypically diverse populations, where the key investigative drug (Liraglutide) was not the most effective choice in all patient cases. Our algorithm therefore offers the potential to inform medical professionals about the effectiveness of drugs at the individual patient-level, and as an advisory tool for examining current clinical guidelines. Future work will investigate our algorithm within other specialties (e.g., oncology), and explore strategies to deal with our study’s various shortcomings (e.g., closer matching between real and virtual drugs, and missing data). 
References Zinman B, Wanner C, Lachin JM, Fitchett D, Bluhmki E, Hantel S, et al. Empagliflozin, Cardiovascular Outcomes, and Mortality in Type 2 Diabetes. N Engl J Med. 2015 Nov 26;373(22):2117–28.
Marso SP, Daniels GH, Brown-Frandsen K, Kristensen P, Mann JFE, Nauck MA, et al. Liraglutide and Cardiovascular Outcomes in Type 2 Diabetes. N Engl J Med. 2016 Jul 28;375(4):311–22.
Marso SP, Bain SC, Consoli A, Eliaschewitz FG, Jódar E, Leiter LA, et al. Semaglutide and Cardiovascular Outcomes in Patients with Type 2 Diabetes. N Engl J Med. 2016 Nov 10;375(19):1834–44.
Nowakowska M, Zghebi SS, Ashcroft DM, Buchan I, Chew-Graham C, Holt T, et al. The comorbidity burden of type 2 diabetes mellitus: patterns, clusters and predictions from a large English primary care cohort. BMC Med. 2019 Jul 25;17(1):145.
Schliep, M. E., Alonzo, C. N., & Morris, M. A. (2017). Beyond RCTs: Innovations in research design and methods to advance implementation science. Evidence-Based Communication Assessment and Intervention, 11(3–4), 82–98. https://doi.org/10.1080/17489539.2017.1394807
Victora, C. G., Habicht, J. P., & Bryce, J. (2004). Evidence-based public health: moving beyond randomized trials. American journal of public health, 94(3), 400–405. https://doi.org/10.2105/ajph.94.3.400
Hernán MA, Robins JM. Using Big Data to Emulate a Target Trial When a Randomized Trial Is Not Available. Am J Epidemiol. 2016 Apr 15;183(8):758–64.
Goodfellow, Ian; Pouget-Abadie, Jean; Mirza, Mehdi; Xu, Bing; Warde-Farley, David; Ozair, Sherjil; Courville, Aaron; Bengio, Yoshua (2014). Generative Adversarial Nets (PDF). Proceedings of the International Conference on Neural Information Processing Systems (NIPS 2014). pp. 2672–2680.
Russell-Jones, D., Vaag, A., Schmitz, O., Sethi, B K,  Lalic, N, Antic, S., Zdravkovic, M., Ravn, G M, Simó, R; Rigato,M.,Fadini,G.P.(2014), Liraglutide vs insulin glargine and placebo in combination with metformin and sulfonylurea therapy in type 2 diabetes mellitus (LEAD-5 met+SU): a randomised controlled trial, Randomized Controlled Trial, Diabetologia 2009 Oct;52(10):2046-55.
NHS Greater Glasgow and Clyde & NHS Tayside Health Board area data https://www.nhsggc.scot/staff-recruitment/staff-resources/research-and-innovation/nhsggc-safe-haven/  
Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., & Courville, A. C. (2017). Improved training of wasserstein gans. Advances in neural information processing systems, 30.
Zheng, X., Dan, C., Aragam, B., Ravikumar, P., & Xing, E. (2020, June). Learning sparse nonparametric dags. In International Conference on Artificial Intelligence and Statistics (pp. 3414-3425). Pmlr.
Abadie, Alberto. “Semiparametric Difference-in-Differences Estimators.” The Review of Economic Studies 72 (2005): 1-19.
Louizos, C., Shalit, U., Mooij, J.M., Sontag, D.A., Zemel, R.S., Welling, M.: Causal Effect Inference with Deep Latent-Variable Models. Preprint at https://arxiv.org/abs/1705.08821 (2017)
Wang, Y., Blei, D.M.: The blessings of multiple causes. Journal of the American Statistical Association 114(528), 1574–1596 (2019)


