Diabetes Risk Prediction Metamodels: Documentation Requirements

Data Management: The MyWayIQ system uses data primarily sourced from linked electronic health records. The specific data elements required for each base model are described in Appendix 1 - feature definitions. Data is extracted and preprocessed using custom scripts, with the imputation of missing values performed using the median value for each feature where required. Each model's data preparation is performed by a dedicated script. These scripts detail the specific steps for data cleaning, transformation, and feature engineering. All code generation, model training and execution was performed within Trusted Research Environments (Data Safe Havens) ensuring GDPR compliance - data extracts were provided by these TREs. The data used for training and calibrating these models were extracted from the Scottish National Diabetes dataset (SCI-Diabetes) and linked datasets. SCI diabetes contains data from all individuals in Scotland with a known diagnosis of diabetes, and provided an identifier (generated by the TRE, demographic and diabetes domain specific information (diagnosis, dates of diagnosis etc). Linked data (by identifier) was taken from inpatient and outpatient code datasets (SMR00 and SMR01), the laboratory results dataset (SCI store), the national prescribing information system (PIS) and the national death dataset (NRS). Where data required by the models are not available within the datasets, a general approach is taken for all - as specified in Appendix 1. Where data is missing, data are imputed using the median value. Where there are 3 or more imputed the model is not run for that individual - either during training or at inference.

Model Design and Training: We employ a combination of literature-based base models and metamodels. The base models are implementations of published risk prediction algorithms for various diabetes-related complications, including amputation, blindness, myocardial infarction (separately for males and females), renal failure and mortality. These models are implemented as functions. The metamodels are linear combinations of the base model outputs, with coefficients trained on Scottish data. The specific coefficients used in the metamodels are hardcoded. The source publications from which the base models were extracted are listed within Appendix_1. Models were chosen from a large number extracted from the literature, on the basis of both domain expertise and post publication clinical usage.

Testing and Validation: The testing and validation process includes internal and external validation of model performance using AUROC (area under the receiver operating characteristic curve) as the primary performance metric. Models were internally cross-validated and then externally validated on a separate dataset from North West London. Models were calibrated on a dataset from a Scottish Health Board. Isotonic calibration was applied, with a calibrator object generated that allows calibration of future predictions. Calibrated performance is shown below.

Table: Metamodel Performance
Model | AUROC  | AUPRC | F1Score | Threshold | Sensitivity | Specificity
AMP   | 0.7083 | 0.020 | 0.0183  | 0.0057    | 0.6382      | 0.6677
BL    | 0.9335 | 0.625 | 0.5234  | 0.1071    | 0.8828      | 0.8123
MIM   | 0.8036 | 0.277 | 0.3325  | 0.0820    | 0.7199      | 0.7643
RR    | 0.8051 | 0.581 | 0.5738  | 0.2500    | 0.7408      | 0.7253
UKR   | 0.7878 | 0.404 | 0.3551  | 0.1111    | 0.6675      | 0.7596
Micro | 0.8423 | 0.598 | 0.5435  | 0.1983    | 0.7632      | 0.7568
Macro | 0.7937 | 0.278 | 0.3301  | 0.0986    | 0.7207      | 0.7398
ANY   | 0.8295 | 0.640 | 0.6048  | 0.2656    | 0.7457      | 0.7554

Table Legend: Performance metrics for metamodel targets in predicting outcomes. Metrics include: AUROC (Area Under the Receiver Operating Characteristic curve, range 0-1), AUPRC (Area Under the Precision-Recall Curve, range 0-1), and F1Score (harmonic mean of precision and recall, range 0-1). Sensitivity (true positive rate) and Specificity (true negative rate) were calculated using the optimal prediction threshold shown. Higher values indicate better performance for all metrics.
Model Targets (all models predict incidence over a 5y window): AMP: Incident amputation | BL: incident blindness | MIM: incident myocardial infarction | RR: death | UKR: incident renal failure | Micro: any microvascular outcome | Macro: any macrovascular outcome | ANY: any outcome

Version Control: Version control was performed using git (outside of trusted research environments) and using a filenaming protocol (within trusted research environments as no version control systems were available within these environments).

Integration with SaMD: The code was passed to the technical team for integration with the production environment.

Post-Market Surveillance: Calibration and assessment of performance of models will be rechecked at each point that they are deployed into a new data environment, and at regular intervals (every 2 years) when operating continuously within one environment.

Algorithm Description & Report: See Document_1_AlgorithmDescription and Appendix_2_metamodel_flow documents for a description of the algorithm. Final performance metrics and calibration plots for each of the metamodels are shown in Appendix_3_5y_recalibration_plots.pdf
