you are an expert prompt writing tool. rewrite the prompt below to optimise the output:

<start rough prompt outline>
"
context: I am writing a tool that uses an LLM to suggest next best actions for a multi-project project management engine. this involves using a github repository as a store for information which will need to be accessed and updated.
I have created pseudo code for this project, and have an example of an api call to gemini, which is the LLM that we will be using for this project:
psudocode is here:
# Main System Components

class TaskAnalysisService:
    def monitor_task_changes(self, previous_tasks, current_tasks):
        """Compare task lists to identify completed and modified tasks"""
        completed_tasks = []
        modified_tasks = []
        new_downstream_tasks = []
        
        # Compare previous and current task states
        # Track task completions, modifications, and new related tasks
        return {
            'completed': completed_tasks,
            'modified': modified_tasks,
            'downstream': new_downstream_tasks
        }
    
    def analyze_completion_patterns(self, task_history):
        """Analyze patterns in task completion"""
        return {
            'avg_completion_time': calculate_average_completion_time(),
            'success_rate': calculate_success_rate(),
            'optimal_times': identify_optimal_suggestion_times()
        }

class GitHubActivityMonitor:
    def track_related_activity(self, task_id, timeframe):
        """Monitor GitHub for activity related to suggested tasks"""
        return {
            'commits': get_related_commits(),
            'pull_requests': get_related_prs(),
            'issues': get_related_issues(),
            'project_velocity': calculate_velocity_impact()
        }

class UserInteractionTracker:
    def track_interactions(self, suggestion_id):
        """Track how users interact with suggestions"""
        return {
            'time_to_action': calculate_time_to_action(),
            'modification_type': identify_modification_pattern(),
            'delegation_info': track_delegation(),
            'subtask_creation': analyze_subtask_patterns()
        }

class TemporalAnalysis:
    def analyze_patterns(self, historical_data):
        """Analyze time-based success patterns"""
        return {
            'optimal_times': find_optimal_suggestion_times(),
            'day_patterns': analyze_day_patterns(),
            'project_phase_impact': analyze_project_phase_correlation()
        }

class FeedbackCollector:
    def collect_feedback(self, suggestion_id):
        """Aggregate feedback from all sources"""
        task_analysis = TaskAnalysisService().monitor_task_changes()
        github_activity = GitHubActivityMonitor().track_related_activity()
        user_interaction = UserInteractionTracker().track_interactions()
        temporal_data = TemporalAnalysis().analyze_patterns()
        
        return self.aggregate_feedback(
            task_analysis,
            github_activity,
            user_interaction,
            temporal_data
        )
    
    def aggregate_feedback(self, *feedback_sources):
        """Combine feedback from all sources into structured format"""
        return {
            'timestamp': get_current_timestamp(),
            'suggestion_data': combine_suggestion_data(),
            'outcome_metrics': calculate_outcome_metrics(),
            'success_indicators': identify_success_indicators()
        }

class FeedbackRepository:
    def update_outcomes(self, feedback_data):
        """Update action_outcomes.jsonl with new feedback"""
        append_to_jsonl('action_outcomes.jsonl', feedback_data)
    
    def update_patterns(self, new_patterns):
        """Update success_patterns.json with new analysis"""
        merge_and_save_json('success_patterns.json', new_patterns)
    
    def update_temporal(self, temporal_data):
        """Update temporal_analysis.json with new patterns"""
        merge_and_save_json('temporal_analysis.json', temporal_data)

class ContextAggregator:
    def aggregate_context(self, query, repo_contents):
        """Combine all context sources for LLM input"""
        feedback_context = self.get_feedback_context()
        return {
            'user_query': query,
            'repository_context': repo_contents,
            'historical_outcomes': feedback_context['outcomes'],
            'success_patterns': feedback_context['patterns'],
            'temporal_insights': feedback_context['temporal']
        }
    
    def get_feedback_context(self):
        """Get relevant feedback data for context"""
        return {
            'outcomes': load_recent_outcomes('action_outcomes.jsonl'),
            'patterns': load_json('success_patterns.json'),
            'temporal': load_json('temporal_analysis.json')
        }

class LLMService:
    def generate_suggestion(self, context):
        """Generate action suggestion using LLM"""
        prompt = self.construct_prompt(context)
        response = self.call_llm_api(prompt)
        return {
            'suggestion': parse_suggestion(response),
            'timestamp': get_current_timestamp(),
            'context_used': summarize_context(context)
        }

# Main Process Runner
class ActionSuggestionSystem:
    def process_query(self, user_query):
        """Main process flow"""
        # 1. Pull latest data
        repo_contents = GitHubService().pull_latest()
        
        # 2. Aggregate context
        context = ContextAggregator().aggregate_context(user_query, repo_contents)
        
        # 3. Generate suggestion
        suggestion = LLMService().generate_suggestion(context)
        
        # 4. Initialize feedback tracking
        FeedbackCollector().initialize_tracking(suggestion['id'])
        
        return suggestion

    def update_feedback(self):
        """Periodic feedback update process"""
        # Run on schedule (e.g., hourly)
        feedback = FeedbackCollector().collect_feedback()
        repo = FeedbackRepository()
        repo.update_outcomes(feedback)
        repo.update_patterns(feedback)
        repo.update_temporal(feedback)
        GitHubService().commit_feedback_updates()

# Cron Jobs
def hourly_task_sync():
    """Sync tasks and update feedback"""
    current_tasks = TodoistService().get_tasks()
    TaskAnalysisService().monitor_task_changes(previous_tasks, current_tasks)
    ActionSuggestionSystem().update_feedback()

def daily_pattern_analysis():
    """Perform daily analysis of patterns"""
    TemporalAnalysis().analyze_patterns()
    FeedbackRepository().update_patterns()


and an example gemini api call is here:

curl "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key=AIzaSyBtG39rcUgNg56BtwFNclGZaQ4DKzktAJs" \
-H 'Content-Type: application/json' \
-X POST \
-d '{
  "contents": [{
    "parts":[{"text": "Explain how AI works"}]
    }]
   }'

github repository url is:
github.com/csainsbury/taskmanagement/

TASK: to create the code that performs the tasks specified in the pseudo code using an api call to the gemini model, and the specified github repo.
"

<end rough prompt outline>

your task is to optimise this prompt for o1 pro